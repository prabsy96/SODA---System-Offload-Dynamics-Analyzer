# SODA â€” System Offload Dynamics Analyzer

![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=flat&logo=pytorch&logoColor=white)
![CUDA](https://img.shields.io/badge/CUDA-enabled-green?logo=nvidia&logoColor=white)
![Profiler](https://img.shields.io/badge/PyTorch%20Profiler-supported-blueviolet)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)
![Citable](https://img.shields.io/badge/Citable-ISPASS%202025-brightgreen)
![System Analysis](https://img.shields.io/badge/System%20Profiler-Enabled-blue)


SODA is a lightweight tool for analyzing the system-level performance dynamics of PyTorch models. It analyzes CPU-GPU interactions during model inference, providing insights into kernel launch overhead, execution dependencies, and opportunities for operator fusion. It is a variant inspired by the **SKIP** tool.

### 1. Overview

SODA helps developers and researchers quickly profile their models to understand performance bottlenecks that are not obvious from high-level latency numbers. By parsing the low-level traces generated by the PyTorch profiler, it quantifies metrics like CUDA runtime overhead, kernel execution time, and GPU idle time, making it easier to identify areas for optimization.

### 2. Background & Prior Work

This tool is derived from and directly inspired by the research presented in the following paper:

> *Characterizing and Optimizing LLM Inference Workloads on CPU-GPU Coupled Architectures*. [Prabhu Vellaisamy, Thomas Labonte, Sourav Chakraborty, Matthew Turner, Samantika Sury, John Paul Shen] ISPASS 2025. 

Please cite as 
````
@INPROCEEDINGS{11096369,
  author={Vellaisamy, Prabhu and Labonte, Thomas and Chakraborty, Sourav and Turner, Matt and Sury, Samantika and Shen, John Paul},
  booktitle={2025 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)}, 
  title={Characterizing and Optimizing LLM Inference Workloads on CPU-GPU Coupled Architectures}, 
  year={2025},
  volume={},
  number={},
  pages={49-61},
  keywords={Couplings;Measurement;Computer architecture;Software;Service-oriented architecture;Performance analysis;Resource management;Kernel;Queueing analysis;Optimization;Accelerators;AI;coupling;benchmarking},
  doi={10.1109/ISPASS64960.2025.00015}}
````

## Installation

**Clone the repository:**

```bash
# Create env
conda create -y -n soda-311 python=3.11
conda activate soda-311

# Install CUDA-enabled PyTorch (cu121 build)
conda install -y -c pytorch -c nvidia pytorch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 pytorch-cuda=12.1

# Clone and install Python deps
git clone https://github.com/prabsy96/soda.git
cd soda
pip install -r requirements.txt
pip install -e .
```

## Quickstart

Run the analysis on a model (e.g., `gpt2`) using synthetic data. The following command will generate trace files and summary reports in the `soda_results/` directory.

For interactive jobs:
```bash
# Run from the root of the repository
./examples/soda_example.sh
```

See `examples/soda_example.py` for a complete example.

For sbatch jobs (you might need to change specifications based on the cluster specs):
```bash
# Run from the root
sbatch ./examples/sbatch.sh
```

## Updates

- 2025-10-19
  - Validated on CUDA 12.6 with PyTorch 2.9.0, torchvision 0.24.0, torchaudio 2.9.0 (H200/ HGPU partition).
  - Added SLURM batch example and guidance for non-interactive conda environments.
  - Improved GPU probe and logging in example scripts.
